{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba07cbb-1839-433d-8a5c-ba1f4c84a760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 58.6ms\n",
      "Speed: 2.3ms preprocess, 58.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 sad, 61.1ms\n",
      "Speed: 1.0ms preprocess, 61.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\n",
      "0: 480x640 1 sad, 54.1ms\n",
      "Speed: 1.4ms preprocess, 54.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-01 18:02:43.453 python[13935:1137918] +[IMKClient subclass]: chose IMKClient_Legacy\n",
      "2024-11-01 18:02:43.453 python[13935:1137918] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 sad, 62.6ms\n",
      "Speed: 1.2ms preprocess, 62.6ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 55.7ms\n",
      "Speed: 1.0ms preprocess, 55.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 63.3ms\n",
      "Speed: 0.9ms preprocess, 63.3ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\n",
      "0: 480x640 1 sad, 54.2ms\n",
      "Speed: 1.0ms preprocess, 54.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\n",
      "0: 480x640 1 sad, 50.5ms\n",
      "Speed: 1.1ms preprocess, 50.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 51.9ms\n",
      "Speed: 1.2ms preprocess, 51.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\n",
      "0: 480x640 1 sad, 52.6ms\n",
      "Speed: 0.8ms preprocess, 52.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 51.7ms\n",
      "Speed: 0.9ms preprocess, 51.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "0: 480x640 1 sad, 51.7ms\n",
      "Speed: 1.0ms preprocess, 51.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "0: 480x640 1 sad, 51.4ms\n",
      "Speed: 0.9ms preprocess, 51.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "0: 480x640 1 sad, 50.3ms\n",
      "Speed: 0.9ms preprocess, 50.3ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\n",
      "0: 480x640 1 sad, 51.6ms\n",
      "Speed: 0.9ms preprocess, 51.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\n",
      "0: 480x640 1 sad, 44.7ms\n",
      "Speed: 0.9ms preprocess, 44.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 53.5ms\n",
      "Speed: 0.8ms preprocess, 53.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "0: 480x640 1 sad, 50.1ms\n",
      "Speed: 0.9ms preprocess, 50.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 48.0ms\n",
      "Speed: 0.9ms preprocess, 48.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "0: 480x640 1 sad, 66.4ms\n",
      "Speed: 1.1ms preprocess, 66.4ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "0: 480x640 1 sad, 58.7ms\n",
      "Speed: 1.0ms preprocess, 58.7ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "0: 480x640 1 sad, 50.0ms\n",
      "Speed: 1.0ms preprocess, 50.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "0: 480x640 1 sad, 51.8ms\n",
      "Speed: 1.0ms preprocess, 51.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\n",
      "0: 480x640 1 sad, 62.8ms\n",
      "Speed: 1.0ms preprocess, 62.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\n",
      "0: 480x640 1 sad, 47.5ms\n",
      "Speed: 1.2ms preprocess, 47.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\n",
      "0: 480x640 1 sad, 56.2ms\n",
      "Speed: 0.9ms preprocess, 56.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "0: 480x640 1 sad, 52.0ms\n",
      "Speed: 1.0ms preprocess, 52.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "0: 480x640 1 sad, 45.0ms\n",
      "Speed: 1.2ms preprocess, 45.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 48.8ms\n",
      "Speed: 0.8ms preprocess, 48.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 49.3ms\n",
      "Speed: 0.8ms preprocess, 49.3ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 46.0ms\n",
      "Speed: 0.7ms preprocess, 46.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\n",
      "0: 480x640 1 sad, 43.8ms\n",
      "Speed: 0.9ms preprocess, 43.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 52.1ms\n",
      "Speed: 0.8ms preprocess, 52.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "0: 480x640 1 sad, 51.0ms\n",
      "Speed: 0.9ms preprocess, 51.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 51.7ms\n",
      "Speed: 0.9ms preprocess, 51.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "0: 480x640 1 sad, 47.6ms\n",
      "Speed: 0.8ms preprocess, 47.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\n",
      "0: 480x640 1 sad, 47.9ms\n",
      "Speed: 0.8ms preprocess, 47.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\n",
      "0: 480x640 1 sad, 57.0ms\n",
      "Speed: 0.9ms preprocess, 57.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\n",
      "0: 480x640 1 sad, 53.7ms\n",
      "Speed: 0.8ms preprocess, 53.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\n",
      "0: 480x640 1 sad, 46.3ms\n",
      "Speed: 0.9ms preprocess, 46.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "0: 480x640 1 sad, 46.9ms\n",
      "Speed: 0.9ms preprocess, 46.9ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 49.5ms\n",
      "Speed: 0.8ms preprocess, 49.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 50.8ms\n",
      "Speed: 12.6ms preprocess, 50.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 49.3ms\n",
      "Speed: 1.0ms preprocess, 49.3ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\n",
      "0: 480x640 1 sad, 48.2ms\n",
      "Speed: 0.9ms preprocess, 48.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\n",
      "0: 480x640 1 sad, 47.2ms\n",
      "Speed: 1.0ms preprocess, 47.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 50.9ms\n",
      "Speed: 0.9ms preprocess, 50.9ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 50.8ms\n",
      "Speed: 0.9ms preprocess, 50.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\n",
      "0: 480x640 1 sad, 49.5ms\n",
      "Speed: 1.0ms preprocess, 49.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 49.9ms\n",
      "Speed: 0.9ms preprocess, 49.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\n",
      "0: 480x640 1 sad, 51.4ms\n",
      "Speed: 1.0ms preprocess, 51.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "0: 480x640 1 sad, 81.7ms\n",
      "Speed: 1.1ms preprocess, 81.7ms inference, 19.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\n",
      "0: 480x640 1 sad, 52.6ms\n",
      "Speed: 1.2ms preprocess, 52.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "0: 480x640 1 sad, 46.2ms\n",
      "Speed: 1.0ms preprocess, 46.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 40.4ms\n",
      "Speed: 1.0ms preprocess, 40.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 48.8ms\n",
      "Speed: 1.0ms preprocess, 48.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 46.8ms\n",
      "Speed: 0.9ms preprocess, 46.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 47.5ms\n",
      "Speed: 0.9ms preprocess, 47.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 45.8ms\n",
      "Speed: 1.0ms preprocess, 45.8ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 43.4ms\n",
      "Speed: 1.0ms preprocess, 43.4ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\n",
      "0: 480x640 1 sad, 48.6ms\n",
      "Speed: 1.0ms preprocess, 48.6ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "0: 480x640 1 sad, 46.5ms\n",
      "Speed: 0.9ms preprocess, 46.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 47.1ms\n",
      "Speed: 1.0ms preprocess, 47.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 46.9ms\n",
      "Speed: 1.0ms preprocess, 46.9ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "0: 480x640 1 sad, 51.0ms\n",
      "Speed: 1.0ms preprocess, 51.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\n",
      "0: 480x640 1 sad, 47.1ms\n",
      "Speed: 1.0ms preprocess, 47.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "0: 480x640 1 sad, 49.6ms\n",
      "Speed: 1.0ms preprocess, 49.6ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\n",
      "0: 480x640 1 sad, 47.2ms\n",
      "Speed: 1.0ms preprocess, 47.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "0: 480x640 1 sad, 46.1ms\n",
      "Speed: 1.0ms preprocess, 46.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 47.5ms\n",
      "Speed: 0.9ms preprocess, 47.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\n",
      "0: 480x640 1 sad, 51.3ms\n",
      "Speed: 1.0ms preprocess, 51.3ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 45.3ms\n",
      "Speed: 0.9ms preprocess, 45.3ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 46.2ms\n",
      "Speed: 1.1ms preprocess, 46.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 46.7ms\n",
      "Speed: 1.0ms preprocess, 46.7ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\n",
      "0: 480x640 1 sad, 47.9ms\n",
      "Speed: 0.9ms preprocess, 47.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 51.5ms\n",
      "Speed: 1.2ms preprocess, 51.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\n",
      "0: 480x640 1 sad, 50.5ms\n",
      "Speed: 0.9ms preprocess, 50.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "0: 480x640 1 sad, 48.9ms\n",
      "Speed: 1.0ms preprocess, 48.9ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "0: 480x640 1 sad, 47.0ms\n",
      "Speed: 0.9ms preprocess, 47.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\n",
      "0: 480x640 1 sad, 48.0ms\n",
      "Speed: 1.0ms preprocess, 48.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 46.0ms\n",
      "Speed: 1.0ms preprocess, 46.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 50.4ms\n",
      "Speed: 1.0ms preprocess, 50.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "0: 480x640 1 sad, 45.0ms\n",
      "Speed: 1.1ms preprocess, 45.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 43.6ms\n",
      "Speed: 1.0ms preprocess, 43.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\n",
      "0: 480x640 1 sad, 51.7ms\n",
      "Speed: 1.0ms preprocess, 51.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "0: 480x640 1 sad, 44.7ms\n",
      "Speed: 1.1ms preprocess, 44.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 46.7ms\n",
      "Speed: 0.9ms preprocess, 46.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 43.3ms\n",
      "Speed: 0.9ms preprocess, 43.3ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 44.2ms\n",
      "Speed: 0.9ms preprocess, 44.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\n",
      "0: 480x640 1 sad, 49.3ms\n",
      "Speed: 1.0ms preprocess, 49.3ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 65.6ms\n",
      "Speed: 1.0ms preprocess, 65.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "0: 480x640 1 sad, 47.7ms\n",
      "Speed: 0.9ms preprocess, 47.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "0: 480x640 1 sad, 50.9ms\n",
      "Speed: 1.0ms preprocess, 50.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\n",
      "0: 480x640 1 sad, 44.5ms\n",
      "Speed: 0.8ms preprocess, 44.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "0: 480x640 1 sad, 56.3ms\n",
      "Speed: 0.9ms preprocess, 56.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "0: 480x640 1 sad, 49.1ms\n",
      "Speed: 0.9ms preprocess, 49.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "0: 480x640 1 sad, 46.6ms\n",
      "Speed: 0.9ms preprocess, 46.6ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\n",
      "0: 480x640 1 sad, 45.2ms\n",
      "Speed: 0.9ms preprocess, 45.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\n",
      "0: 480x640 1 sad, 45.4ms\n",
      "Speed: 0.9ms preprocess, 45.4ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 44.1ms\n",
      "Speed: 0.9ms preprocess, 44.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\n",
      "0: 480x640 1 sad, 45.8ms\n",
      "Speed: 0.9ms preprocess, 45.8ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 49.3ms\n",
      "Speed: 0.8ms preprocess, 49.3ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 44.5ms\n",
      "Speed: 0.9ms preprocess, 44.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 42.8ms\n",
      "Speed: 0.9ms preprocess, 42.8ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\n",
      "0: 480x640 1 sad, 47.8ms\n",
      "Speed: 0.7ms preprocess, 47.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\n",
      "0: 480x640 1 sad, 44.4ms\n",
      "Speed: 0.7ms preprocess, 44.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\n",
      "0: 480x640 1 sad, 47.0ms\n",
      "Speed: 0.8ms preprocess, 47.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\n",
      "0: 480x640 1 sad, 43.7ms\n",
      "Speed: 0.8ms preprocess, 43.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 47.0ms\n",
      "Speed: 0.9ms preprocess, 47.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 48.1ms\n",
      "Speed: 0.9ms preprocess, 48.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 46.4ms\n",
      "Speed: 1.0ms preprocess, 46.4ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\n",
      "0: 480x640 1 sad, 61.7ms\n",
      "Speed: 0.9ms preprocess, 61.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\n",
      "0: 480x640 1 sad, 57.0ms\n",
      "Speed: 1.0ms preprocess, 57.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\n",
      "0: 480x640 1 sad, 55.9ms\n",
      "Speed: 0.8ms preprocess, 55.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\n",
      "0: 480x640 1 sad, 59.3ms\n",
      "Speed: 1.3ms preprocess, 59.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\n",
      "0: 480x640 1 sad, 46.6ms\n",
      "Speed: 0.9ms preprocess, 46.6ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\n",
      "0: 480x640 1 sad, 48.9ms\n",
      "Speed: 0.9ms preprocess, 48.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 55.7ms\n",
      "Speed: 0.9ms preprocess, 55.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 51.3ms\n",
      "Speed: 0.9ms preprocess, 51.3ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 45.7ms\n",
      "Speed: 0.9ms preprocess, 45.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\n",
      "0: 480x640 1 sad, 53.0ms\n",
      "Speed: 1.1ms preprocess, 53.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\n",
      "0: 480x640 1 sad, 47.4ms\n",
      "Speed: 0.8ms preprocess, 47.4ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 48.7ms\n",
      "Speed: 0.8ms preprocess, 48.7ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\n",
      "0: 480x640 1 sad, 49.6ms\n",
      "Speed: 1.0ms preprocess, 49.6ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 45.5ms\n",
      "Speed: 0.8ms preprocess, 45.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\n",
      "0: 480x640 1 sad, 51.0ms\n",
      "Speed: 1.1ms preprocess, 51.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 50.1ms\n",
      "Speed: 1.1ms preprocess, 50.1ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "0: 480x640 1 sad, 51.7ms\n",
      "Speed: 1.0ms preprocess, 51.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 48.3ms\n",
      "Speed: 0.8ms preprocess, 48.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 49.8ms\n",
      "Speed: 0.9ms preprocess, 49.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 55.6ms\n",
      "Speed: 1.0ms preprocess, 55.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\n",
      "0: 480x640 1 sad, 46.7ms\n",
      "Speed: 0.9ms preprocess, 46.7ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\n",
      "0: 480x640 1 sad, 46.6ms\n",
      "Speed: 1.2ms preprocess, 46.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\n",
      "0: 480x640 1 sad, 52.0ms\n",
      "Speed: 1.1ms preprocess, 52.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 50.3ms\n",
      "Speed: 1.1ms preprocess, 50.3ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\n",
      "0: 480x640 1 sad, 46.7ms\n",
      "Speed: 1.0ms preprocess, 46.7ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\n",
      "0: 480x640 1 sad, 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\n",
      "0: 480x640 1 sad, 50.7ms\n",
      "Speed: 1.0ms preprocess, 50.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\n",
      "0: 480x640 1 sad, 52.1ms\n",
      "Speed: 1.1ms preprocess, 52.1ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 51.4ms\n",
      "Speed: 1.2ms preprocess, 51.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 51.3ms\n",
      "Speed: 1.0ms preprocess, 51.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 44.8ms\n",
      "Speed: 1.0ms preprocess, 44.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "0: 480x640 1 sad, 48.9ms\n",
      "Speed: 1.0ms preprocess, 48.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 49.0ms\n",
      "Speed: 1.0ms preprocess, 49.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 49.8ms\n",
      "Speed: 1.3ms preprocess, 49.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\n",
      "0: 480x640 1 sad, 49.4ms\n",
      "Speed: 0.8ms preprocess, 49.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 47.4ms\n",
      "Speed: 0.9ms preprocess, 47.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 49.4ms\n",
      "Speed: 0.9ms preprocess, 49.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 49.1ms\n",
      "Speed: 0.9ms preprocess, 49.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\n",
      "0: 480x640 1 sad, 46.1ms\n",
      "Speed: 0.9ms preprocess, 46.1ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 50.2ms\n",
      "Speed: 0.9ms preprocess, 50.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\n",
      "0: 480x640 1 sad, 47.3ms\n",
      "Speed: 1.1ms preprocess, 47.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\n",
      "0: 480x640 1 sad, 48.2ms\n",
      "Speed: 0.9ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 51.9ms\n",
      "Speed: 1.4ms preprocess, 51.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\n",
      "0: 480x640 1 sad, 47.0ms\n",
      "Speed: 1.0ms preprocess, 47.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\n",
      "0: 480x640 1 sad, 47.8ms\n",
      "Speed: 1.1ms preprocess, 47.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\n",
      "0: 480x640 1 sad, 45.0ms\n",
      "Speed: 1.1ms preprocess, 45.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\n",
      "0: 480x640 1 sad, 51.2ms\n",
      "Speed: 1.1ms preprocess, 51.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\n",
      "0: 480x640 1 sad, 48.0ms\n",
      "Speed: 0.9ms preprocess, 48.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\n",
      "0: 480x640 1 sad, 45.2ms\n",
      "Speed: 0.9ms preprocess, 45.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\n",
      "0: 480x640 1 sad, 47.5ms\n",
      "Speed: 0.9ms preprocess, 47.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 46.4ms\n",
      "Speed: 1.3ms preprocess, 46.4ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 46.4ms\n",
      "Speed: 1.0ms preprocess, 46.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\n",
      "0: 480x640 1 sad, 53.2ms\n",
      "Speed: 1.2ms preprocess, 53.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\n",
      "0: 480x640 1 sad, 49.6ms\n",
      "Speed: 1.0ms preprocess, 49.6ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\n",
      "0: 480x640 1 sad, 47.7ms\n",
      "Speed: 0.9ms preprocess, 47.7ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 42.3ms\n",
      "Speed: 0.9ms preprocess, 42.3ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 48.3ms\n",
      "Speed: 0.9ms preprocess, 48.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\n",
      "0: 480x640 1 sad, 49.3ms\n",
      "Speed: 1.0ms preprocess, 49.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\n",
      "0: 480x640 1 sad, 47.1ms\n",
      "Speed: 1.1ms preprocess, 47.1ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "0: 480x640 1 sad, 48.4ms\n",
      "Speed: 0.8ms preprocess, 48.4ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox, Toplevel, Label, Button\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "from keras_facenet import FaceNet\n",
    "from ultralytics import YOLO\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from PIL import Image, ImageTk\n",
    "import imgaug.augmenters as iaa\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Initialize YOLO and FaceNet\n",
    "yolo_model = YOLO('/Users/klnimri/Downloads/FaceReco.pt')\n",
    "embedder = FaceNet()\n",
    "\n",
    "# Paths for saving embeddings and attendance records\n",
    "embeddings_path = \"/Users/klnimri/Desktop/DeepLearningFinalProject/face_embeddings.json\"\n",
    "attendance_path = \"/Users/klnimri/Desktop/DeepLearningFinalProject/attendance_records.json\"\n",
    "\n",
    "# Initialize embeddings database and attendance records\n",
    "database = {}\n",
    "attendance_records = {}\n",
    "\n",
    "# Load existing embeddings from file\n",
    "def load_embeddings():\n",
    "    global database\n",
    "    if os.path.exists(embeddings_path) and os.path.getsize(embeddings_path) > 0:\n",
    "        with open(embeddings_path, \"r\") as file:\n",
    "            database = json.load(file)\n",
    "        for student_id in database:\n",
    "            database[student_id]['embedding'] = np.array(database[student_id]['embedding'])\n",
    "    else:\n",
    "        database = {}\n",
    "\n",
    "# Save embeddings to file\n",
    "def save_embeddings():\n",
    "    save_data = {k: {'name': v['name'], 'embedding': v['embedding'].tolist()} for k, v in database.items()}\n",
    "    with open(embeddings_path, \"w\") as file:\n",
    "        json.dump(save_data, file)\n",
    "\n",
    "# Load existing attendance records\n",
    "def load_attendance_records():\n",
    "    global attendance_records\n",
    "    if os.path.exists(attendance_path) and os.path.getsize(attendance_path) > 0:\n",
    "        with open(attendance_path, \"r\") as file:\n",
    "            attendance_records = json.load(file)\n",
    "    else:\n",
    "        attendance_records = {}\n",
    "\n",
    "# Save attendance records to file\n",
    "def save_attendance_records():\n",
    "    with open(attendance_path, \"w\") as file:\n",
    "        json.dump(attendance_records, file, indent=4)\n",
    "\n",
    "# Define augmentations\n",
    "augmentation_pipeline = iaa.Sequential([\n",
    "    iaa.Affine(scale=(0.9, 1.1), rotate=(-10, 10)),\n",
    "    iaa.Fliplr(0.5),\n",
    "])\n",
    "\n",
    "# Capture, augment, and save embeddings\n",
    "def create_student():\n",
    "    def capture_and_save():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            messagebox.showerror(\"Error\", \"Could not access webcam.\")\n",
    "            return\n",
    "\n",
    "        results = yolo_model(frame)\n",
    "        if len(results[0].boxes) > 0:\n",
    "            x1, y1, x2, y2 = map(int, results[0].boxes[0].xyxy[0])\n",
    "            face = frame[y1:y2, x1:x2]\n",
    "            face_rgb = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "            embeddings = []\n",
    "\n",
    "            for _ in range(5):\n",
    "                augmented_face = augmentation_pipeline(image=face_rgb)\n",
    "                embedding = embedder.embeddings([augmented_face])[0]\n",
    "                embeddings.append(embedding)\n",
    "\n",
    "            avg_embedding = np.mean(embeddings, axis=0)\n",
    "\n",
    "            name = name_entry.get()\n",
    "            student_id = id_entry.get()\n",
    "            if name and student_id:\n",
    "                database[student_id] = {'name': name, 'embedding': avg_embedding}\n",
    "                save_embeddings()\n",
    "                messagebox.showinfo(\"Success\", f\"{name} has been enrolled!\")\n",
    "                signup_win.destroy()\n",
    "\n",
    "    signup_win = Toplevel(root)\n",
    "    signup_win.title(\"Sign Up\")\n",
    "    center_window(signup_win, 300, 200)  # Center the Sign Up window\n",
    "\n",
    "    Label(signup_win, text=\"Name:\").pack()\n",
    "    name_entry = tk.Entry(signup_win)\n",
    "    name_entry.pack()\n",
    "    Label(signup_win, text=\"Student ID:\").pack()\n",
    "    id_entry = tk.Entry(signup_win)\n",
    "    id_entry.pack()\n",
    "    Button(signup_win, text=\"Capture and Save\", command=capture_and_save).pack(pady=10)\n",
    "\n",
    "# Center window on screen\n",
    "def center_window(window, width, height):\n",
    "    screen_width = window.winfo_screenwidth()\n",
    "    screen_height = window.winfo_screenheight()\n",
    "    x = (screen_width - width) // 2\n",
    "    y = (screen_height - height) // 2\n",
    "    window.geometry(f\"{width}x{height}+{x}+{y}\")\n",
    "\n",
    "# Display camera feed with real-time recognition\n",
    "def update_camera_feed():\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        results = yolo_model(frame)\n",
    "        if len(results[0].boxes) > 0:\n",
    "            x1, y1, x2, y2 = map(int, results[0].boxes[0].xyxy[0])\n",
    "            face = frame[y1:y2, x1:x2]\n",
    "            face_rgb = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "            embedding = embedder.embeddings([face_rgb])[0]\n",
    "\n",
    "            best_match = None\n",
    "            best_similarity = 0\n",
    "            for student_id, data in database.items():\n",
    "                similarity = cosine_similarity([embedding], [data['embedding']])[0][0]\n",
    "                if similarity > best_similarity:\n",
    "                    best_similarity = similarity\n",
    "                    best_match = (data['name'], student_id)\n",
    "\n",
    "            if best_similarity >= 0.8 and best_match:\n",
    "                name, student_id = best_match\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f\"{name} ({student_id})\", (x1, y1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img = Image.fromarray(frame_rgb)\n",
    "        imgtk = ImageTk.PhotoImage(image=img)\n",
    "        camera_label.imgtk = imgtk\n",
    "        camera_label.configure(image=imgtk)\n",
    "\n",
    "    camera_label.after(20, update_camera_feed)  # Reduce delay here\n",
    "\n",
    "# Take attendance\n",
    "def take_attendance():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        return\n",
    "\n",
    "    results = yolo_model(frame)\n",
    "    if len(results[0].boxes) > 0:\n",
    "        x1, y1, x2, y2 = map(int, results[0].boxes[0].xyxy[0])\n",
    "        face = frame[y1:y2, x1:x2]\n",
    "        face_rgb = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "        embedding = embedder.embeddings([face_rgb])[0]\n",
    "\n",
    "        best_match = None\n",
    "        best_similarity = 0\n",
    "        for student_id, data in database.items():\n",
    "            similarity = cosine_similarity([embedding], [data['embedding']])[0][0]\n",
    "            if similarity > best_similarity:\n",
    "                best_similarity = similarity\n",
    "                best_match = (data['name'], student_id)\n",
    "\n",
    "        if best_similarity >= 0.7:\n",
    "            name, student_id = best_match\n",
    "            now = datetime.now()\n",
    "            date_str = now.strftime(\"%Y-%m-%d\")\n",
    "            time_str = now.strftime(\"%H:%M:%S\")\n",
    "\n",
    "            if date_str not in attendance_records:\n",
    "                attendance_records[date_str] = {}\n",
    "\n",
    "            if student_id not in attendance_records[date_str]:\n",
    "                attendance_records[date_str][student_id] = {'name': name, 'times': []}\n",
    "            \n",
    "            attendance_records[date_str][student_id]['times'].append(time_str)\n",
    "            save_attendance_records()\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"{name} ({student_id})\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            messagebox.showinfo(\"Attendance\", f\"Attendance recorded for {name} (ID: {student_id})\")\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img = Image.fromarray(frame_rgb)\n",
    "    imgtk = ImageTk.PhotoImage(image=img)\n",
    "    camera_label.imgtk = imgtk\n",
    "    camera_label.configure(image=imgtk)\n",
    "\n",
    "# Show attendance records\n",
    "def show_records():\n",
    "    records_win = Toplevel(root)\n",
    "    records_win.title(\"Attendance Records\")\n",
    "    center_window(records_win, 400, 400)  # Center the Records window\n",
    "\n",
    "    for date, students in attendance_records.items():\n",
    "        date_label = Label(records_win, text=f\"{date}\")\n",
    "        date_label.pack()\n",
    "\n",
    "        for student_id, data in students.items():\n",
    "            attendance_count = len(data['times'])\n",
    "            record_label = Label(records_win, text=f\"{data['name']} (ID: {student_id}) - Times: {', '.join(data['times'])} - Count: {attendance_count}\")\n",
    "            record_label.pack()\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"Attendance System\")\n",
    "center_window(root, 650, 650)  \n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 320)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)\n",
    "\n",
    "camera_label = tk.Label(root)\n",
    "camera_label.pack()\n",
    "\n",
    "tk.Button(root, text=\"Sign Up\", command=create_student).pack(pady=10)\n",
    "tk.Button(root, text=\"Take Attendance\", command=take_attendance).pack(pady=10)\n",
    "tk.Button(root, text=\"Records\", command=show_records).pack(pady=10)\n",
    "\n",
    "load_embeddings()\n",
    "load_attendance_records()\n",
    "root.after(0, update_camera_feed)\n",
    "root.mainloop()\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747bdc15-6d22-4320-a326-e81a9dbd93d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
